module generate-sdf
imports
  libstratego-lib
  libstratego-sglr
  include/Template
  lib/sdf-desugar
  lib/sdf-parenthesize
  lib/sdf-pretty-print
  analysis
  generation-utils
  sdf2conflicts

strategies

  to-sdf:
    x -> <sdf2conflicts; try(sdf-to-string)> d|[
      definition
      m*
      module Completion-Support
      exports
        lexical syntax
          [A-Za-z0-9]* "CONTENTCOMPLETE" [0-9]+ -> CONTENTCOMPLETE {avoid}
        context-free syntax
          p*
    ]|
    with
      // all imported modules
      m* := <all-keys-IsImported; map(Module; to-sdf-module);
             // prepend Completion-Support include to first module
             (  ["module"#([id, [imports(![ i|[ Completion-Support ]| |<id>]) | id], id]) |id]
             <+ ["module"#([id, \[] -> [imports([ i|[ Completion-Support ]| ])]\, id]) |id])>;
      // CONTENTCOMPLETE injections
      p* := <all-keys-Declaration; map(sort-to-contentcomplete)>
      // INSERTIONs
      // FIXME: do not generate an insertion when one already exists
      //p2* := <all-keys-Declaration; map(sort-to-insertion)> p1*;

  to-sdf-module:
    x -> m|[
      module M
      is*
      exports
        context-free syntax
          p*
      s*
    ]|
    with
      // module name and imports
      if <collect-one(?Module(M, import*, section*))> x then
        is* := <   \Imports([]) -> []\
                <+ \Imports(t) -> [imports(<map(\Import(M) -> i|[ M ]|\)> t)]\> import*
      else
        (M, is) := ("example", [])
      end
    with
      // main productions
      p* := <collect-om(template-production-to-sdf)> x
    with
      // lexical restrictions
      let ends-with-identifier-char =
        where(explode-string; un-double-quote-chars; last; (is-alphanum + '_'))
      in
        A* := <collect-om(?lit(<ends-with-identifier-char>));
               nub; string-sort-ex> p*;
        if !A* => [] then
          restriction* := []
        else
          restriction* := [|[ lexical restrictions
                                A* -/- [A-Za-z0-9\_\-] ]|]
        end
      end
      // rejections
      // let is-identifier-ish =
      //       where(explode-string; un-double-quote-chars; all(is-alphanum))
      //     to-rejection =
      //       \L -> p|[ L -> ID {reject} ]|\
      // in
      //   p2* := <collect-om(?lit(<is-identifier-ish>));
      //           nub; string-sort-ex; map(to-rejection)> p*;
      //   if !p2* => [] then
      //     rejection* := []
      //   else
      //     rejection* := [|[ context-free syntax p2* ]|]
      //   end
      // end;
      // SDF grammars
      // (each one is put in a separate `exports' section because SDF doesn't
      //  use a flat list for the grammars within a section, but a tree...)
    with
      section'* := <filter(\SdfGrammar(t) -> exports(<try(rewrite-sortcons-references)> t)\)> section*
    with
      s* := [restriction*, section'*]

  rewrite-sortcons-references:
    context-free-priorities(t) -> context-free-priorities(t')
    with
      let rewrite =
            \SortCons(sort, cons) ->
              <Template; template-production-to-sdf-no-attrs> (sort, cons)\
      in
        t' := <alltd(
                  \simple-ref-group(ref) -> simple-group(<rewrite> ref)\
                + \prods-ref-group(ref*) -> prods-group(<map(rewrite)> ref*)\
                + \assoc-ref-group(a, ref*) -> assoc-group(a, <map(rewrite)> ref*)\
              )> t
      end

  sdf-to-string =
    bottomup(try(
        \conc-grammars(x, context-free-syntax([])) -> x\
      + \conc-grammars(x, lexical-syntax([])) -> x\
      + \conc-grammars(x, lexical-restrictions([])) -> x\
    ));
    sdf-desugar;
    sdf-parenthesize;
    pp-sdf-string

  template-production-to-sdf-no-attrs:
    TemplateProduction(S', t, _) -> p|[ A* -> S' ]|
    with
      A* := <template-to-sdf> t

  template-production-to-sdf:
    TemplateProduction(S', t, attrs') -> p|[ A* -> S' attrs' ]|
    with
      A* := <template-to-sdf> t

  template-to-sdf:
    Template(e* @[_|_]) -> A*
    with
      A* := <newlines-switch(id, trim-trailing-layout, trim-leading-layout);
             combine-consecutive-newlines;
             filter(template-element-to-sdf);
             flatten-list> e*

  template-to-sdf:
    Template([]) -> []

  template-element-to-sdf:
    Newline(_){ /* neither Leading() nor Trailing() */ } -> A|[ "\\n" ]|
    where not(use-no-newlines)

  template-element-to-sdf:
    Newline(_) -> A|[ "\\n" ]|
    where use-leading-newlines
    where not(has-anno(|Leading()))

  template-element-to-sdf:
    Newline(_) -> A|[ "\\n" ]|
    where use-trailing-newlines
    where not(has-anno(|Trailing()))

  template-element-to-sdf:
    String(x) -> <string-to-sdf> x

  // Insert "\n" into generated grammar whenever
  // 1) leading or trailing newlines is enabled
  // 2) the sort itself does not contain a leading resp. trailing newline
  // 3) the placeholder is on its own on the line
  template-element-to-sdf:
    p@ Placeholder(_, Sort(sort), None(), _){Blank()} -> t'
    with
      t := <placeholder-to-sdf> p;
      t' := <newlines-switch(id,
        if not(<sort-has-leading-newline> sort) then
          ?A; !A|[ ("\\n" A) ]|
        end,
        if not(<sort-has-trailing-newline> sort) then
          ?A; !A|[ (A "\\n") ]|
        end
      )> t

  // FIXME: generates suboptimal SDF (bad AST)
  template-element-to-sdf:
    p@ Placeholder(_, Sort(sort), <?Plus() + ?Star() + ?Option()>, _){Blank()} -> t'
    with
      t := <placeholder-to-sdf> p;
      t' := <newlines-switch(id,
        if not(<sort-has-leading-newline> sort) then
          ?A; !A|[ ("\\n" A)? ]|
        end,
        if not(<sort-has-trailing-newline> sort) then
          ?A; !A|[ (A "\\n")? ]|
        end
      )> t

  template-element-to-sdf:
    Placeholder(_, _, _, _){} -> <placeholder-to-sdf>

  placeholder-to-sdf:
    Placeholder(_, Sort(S'), None(), _) -> A|[ S' ]|

  // TODO: this needs improvement, too much duplication and not readable enough

  placeholder-to-sdf:
    Placeholder(_, Sort(S), Star(), Options(option*)) -> A|[ S* ]|
    where <not(one(Separator(not(all-whitespace))))> option*

  placeholder-to-sdf:
    Placeholder(_, Sort(S), Star(), Options(option*)) -> A|[ { S L }* ]|
    where <one(Separator(not(all-whitespace)))> option*
    with L := <separator-to-literal> option*

  placeholder-to-sdf:
    Placeholder(_, Sort(S), Plus(), Options(option*)) -> A|[ S+ ]|
    where <not(one(Separator(not(all-whitespace))))> option*

  placeholder-to-sdf:
    Placeholder(_, Sort(S), Plus(), Options(option*)) -> A|[ { S L }+ ]|
    where <one(Separator(not(all-whitespace)))> option*
    with L := <separator-to-literal> option*

  // name conflicts with is-whitespace from the library
  xxx-is-whitespace =
    // if use-no-newlines then
      ' ' + '\t' + '\r' + '\n'
    // else
    //   ' ' + '\t' + '\r'
    // end

  all-whitespace = string-as-chars(all(xxx-is-whitespace))

  remove-whitespace = string-as-chars(filter(not(xxx-is-whitespace)))

  separator-to-literal =
    !lit(<collect-one(?Separator(<remove-whitespace>)); escape; double-quote>)

  placeholder-to-sdf:
    Placeholder(_, Sort(S'), Option(), _) -> A|[ S'? ]|

  sort-to-contentcomplete:
    S' -> p|[ CONTENTCOMPLETE -> S' {cons("WATER"), avoid} ]|

  sort-to-insertion:
    S'@sort(x) -> p|[ -> S' {cons("INSERTION"), recover} ]|

strategies

  /**
   * Sorts a list of terms on the outermost string within each term.
   */
  string-sort-ex =
    qsort(
      \(a, b) -> (<collect-one(is-string)> a, <collect-one(is-string)> b)\;
      string-lt
    )

  string-to-sdf =
    string-identifier-tokenize;
    // FIXME: Case insensitive literals need ci-lit/single-quote.
    map({raw, sdf:
      ?raw; escape; !lit(<double-quote>); ?sdf;
      if <explode-string; last; (is-alphanum + '_')> raw then
        rules(Restrictions :+= sdf)
      end
    })

  /**
   * Split on the edges delimiting identifiers and then strip layout
   * from the resulting tokens and remove empty tokens.
   * E.g. " func ( x y )" => ["func", "(", "x", "y", ")"]
   */
  string-identifier-tokenize =
    // FIXME: Use layout defined by the language.
    let is-layout = ' ' + '\t' + '\n' + '\r'
        strip-layout = string-as-chars(filter(not(is-layout)))
    in
      // FIXME: Use identifier lexical defined by the language.
      string-edge-tokenize(is-alphanum + '_');
      filter(strip-layout; not(""))
    end

  /**
   * @see edge-tokenize
   */
  string-edge-tokenize(s) =
    explode-string;
    edge-tokenize(s);
    map(implode-string)

  /**
   * Edge-triggered tokenizer; a new token starts whenever s starts
   * succeeding or starts failing, i.e. when for two consecutive list items
   * s succeeds on the first item but s fails on the second item or
   * s fails on the first item and s succeeds on the second item.
   */
  edge-tokenize(s) =
    ?[first | tail];
    if second := <Hd> tail then
      tokens := <edge-tokenize(s)> tail;
      if (<s> first; <not(s)> second) +
         (<not(s)> first; <s> second) then
        ![[first] | tokens]
      else
        [firstToken | restTokens] := tokens;
        ![[first | firstToken] | restTokens]
      end
    else
      ![[first]]
    end
